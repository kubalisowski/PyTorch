{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOpHCSFgBenNhmUxodeyboD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kubalisowski/PyTorch/blob/main/pytorch_1_0_primitive_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wjzUlwFj2UQ1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn # nn contains all of PyTorch's building blocks for neural networks\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Check PyTorch version\n",
        "# torch.__version__"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create *known* parameters\n",
        "weight = 0.7\n",
        "bias = 0.3\n",
        "\n",
        "# Create data\n",
        "start = 0\n",
        "end = 1\n",
        "step = 0.02\n",
        "X = torch.arange(start, end, step).unsqueeze(dim=1)\n",
        "y = weight * X + bias\n",
        "\n",
        "X[:10], y[:10]"
      ],
      "metadata": {
        "id": "c-O0wfN72c1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create train/test split\n",
        "train_split = int(0.8 * len(X)) # 80% of data used for training set, 20% for testing\n",
        "X_train, y_train = X[:train_split], y[:train_split]\n",
        "X_test, y_test = X[train_split:], y[train_split:]\n",
        "\n",
        "len(X_train), len(y_train), len(X_test), len(y_test)"
      ],
      "metadata": {
        "id": "L9ujWnjo2fQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_predictions(train_data=X_train,\n",
        "                     train_labels=y_train,\n",
        "                     test_data=X_test,\n",
        "                     test_labels=y_test,\n",
        "                     predictions=None):\n",
        "  \"\"\"\n",
        "  Plots training data, test data and compares predictions.\n",
        "  \"\"\"\n",
        "  plt.figure(figsize=(10, 7))\n",
        "\n",
        "  # Plot training data in blue\n",
        "  plt.scatter(train_data, train_labels, c=\"b\", s=4, label=\"Training data\")\n",
        "\n",
        "  # Plot test data in green\n",
        "  plt.scatter(test_data, test_labels, c=\"g\", s=4, label=\"Testing data\")\n",
        "\n",
        "  if predictions is not None:\n",
        "    # Plot the predictions in red (predictions were made on the test data)\n",
        "    plt.scatter(test_data, predictions, c=\"r\", s=4, label=\"Predictions\")\n",
        "\n",
        "  # Show the legend\n",
        "  plt.legend(prop={\"size\": 14});"
      ],
      "metadata": {
        "id": "5xLtZsqf3JTk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_predictions();"
      ],
      "metadata": {
        "id": "4ZrpjBPc3pua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Linear Regression model class\n",
        "class LinearRegressionModel(nn.Module): # <- almost everything in PyTorch is a nn.Module (think of this as neural network lego blocks)\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.weights = nn.Parameter(torch.randn(1, # <- start with random weights (this will get adjusted as the model learns)\n",
        "                                                dtype=torch.float), # <- PyTorch loves float32 by default\n",
        "                                   requires_grad=True) # <- can we update this value with gradient descent?)\n",
        "\n",
        "        self.bias = nn.Parameter(torch.randn(1, # <- start with random bias (this will get adjusted as the model learns)\n",
        "                                            dtype=torch.float), # <- PyTorch loves float32 by default\n",
        "                                requires_grad=True) # <- can we update this value with gradient descent?))\n",
        "\n",
        "    # Forward defines the computation in the model\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor: # <- \"x\" is the input data (e.g. training/testing features)\n",
        "        return self.weights * x + self.bias # <- this is the linear regression formula (y = m*x + b)"
      ],
      "metadata": {
        "id": "E2lIgcCT4PWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set manual seed since nn.Parameter are randomly initialized\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Create an instance of the model (this is a subclass of nn.Module that contains nn.Parameter(s))\n",
        "model_0 = LinearRegressionModel()\n",
        "\n",
        "# Check the nn.Parameter(s) within the nn.Module subclass we created\n",
        "list(model_0.parameters())"
      ],
      "metadata": {
        "id": "tlOyvVqa4VVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List named parameters\n",
        "model_0.state_dict()"
      ],
      "metadata": {
        "id": "bwC-cPKi4ayY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions with model\n",
        "with torch.inference_mode():\n",
        "    y_preds = model_0(X_test)\n",
        "\n",
        "# Note: in older PyTorch code you might also see torch.no_grad()\n",
        "# with torch.no_grad():\n",
        "#   y_preds = model_0(X_test)"
      ],
      "metadata": {
        "id": "nQioRLea4dDf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the predictions\n",
        "print(f\"Number of testing samples: {len(X_test)}\")\n",
        "print(f\"Number of predictions made: {len(y_preds)}\")\n",
        "print(f\"Predicted values:\\n{y_preds}\")"
      ],
      "metadata": {
        "id": "fyfun9Dd6Prv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_predictions(predictions=y_preds)"
      ],
      "metadata": {
        "id": "Texj3F_m4mmQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### TRAIN MODEL ###"
      ],
      "metadata": {
        "id": "ZR3cakHK4zK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the loss function\n",
        "loss_fn = nn.L1Loss() # MAE loss is same as L1Loss\n",
        "\n",
        "# Create the optimizer\n",
        "optimizer = torch.optim.SGD(params=model_0.parameters(), # parameters of target model to optimize\n",
        "                            lr=0.01) # learning rate (how much the optimizer should change parameters at each step, higher=more (less stable), lower=less (might take a long time)"
      ],
      "metadata": {
        "id": "hCOhM-gd6tQ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "# Set the number of epochs (how many times the model will pass over the training data)\n",
        "epochs = 100\n",
        "\n",
        "# Create empty loss lists to track values\n",
        "train_loss_values = []\n",
        "test_loss_values = []\n",
        "epoch_count = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    ### Training\n",
        "\n",
        "    # Put model in training mode (this is the default state of a model)\n",
        "    model_0.train()\n",
        "\n",
        "    # 1. Forward pass on train data using the forward() method inside\n",
        "    y_pred = model_0(X_train)\n",
        "    # print(y_pred)\n",
        "\n",
        "    # 2. Calculate the loss (how different are our models predictions to the ground truth)\n",
        "    loss = loss_fn(y_pred, y_train)\n",
        "\n",
        "    # 3. Zero grad of the optimizer\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # 4. Loss backwards\n",
        "    loss.backward()\n",
        "\n",
        "    # 5. Progress the optimizer\n",
        "    optimizer.step()\n",
        "\n",
        "    ### Testing\n",
        "\n",
        "    # Put the model in evaluation mode\n",
        "    model_0.eval()\n",
        "\n",
        "    with torch.inference_mode():\n",
        "      # 1. Forward pass on test data\n",
        "      test_pred = model_0(X_test)\n",
        "\n",
        "      # 2. Caculate loss on test data\n",
        "      test_loss = loss_fn(test_pred, y_test.type(torch.float)) # predictions come in torch.float datatype, so comparisons need to be done with tensors of the same type\n",
        "\n",
        "      # Print out what's happening\n",
        "      if epoch % 10 == 0:\n",
        "            epoch_count.append(epoch)\n",
        "            train_loss_values.append(loss.detach().numpy())\n",
        "            test_loss_values.append(test_loss.detach().numpy())\n",
        "            print(f\"Epoch: {epoch} | MAE Train Loss: {loss} | MAE Test Loss: {test_loss} \")"
      ],
      "metadata": {
        "id": "BbCUD_O357Nm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "P6TWDw1m3IYY"
      }
    }
  ]
}